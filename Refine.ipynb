{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "max_pad_len = 174\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  8732  files\n"
     ]
    }
   ],
   "source": [
    "# Load various imports \n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "# Set the path to the full UrbanSound dataset \n",
    "fulldatasetpath = 'audio/'\n",
    "\n",
    "metadata = pd.read_csv('metadata/UrbanSound8K.csv')\n",
    "\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    \n",
    "    class_label = row[\"class\"]\n",
    "    data = extract_features(file_name)\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) \n",
    "\n",
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "num_rows = 40\n",
    "num_columns = 174\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 39, 173, 16)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 19, 86, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 19, 86, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 18, 85, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 42, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 9, 42, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 41, 64)         8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 19, 128)        32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 44,602\n",
      "Trainable params: 44,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1747/1747 [==============================] - 2s 930us/step\n",
      "Pre-training accuracy: 12.1351%\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6985 samples, validate on 1747 samples\n",
      "Epoch 1/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 1.7911 - accuracy: 0.3641 - val_loss: 1.7566 - val_accuracy: 0.4247\n",
      "Epoch 2/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 1.5209 - accuracy: 0.4732 - val_loss: 1.5532 - val_accuracy: 0.4682\n",
      "Epoch 3/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 1.4020 - accuracy: 0.5042 - val_loss: 1.4463 - val_accuracy: 0.5329\n",
      "Epoch 4/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 1.3091 - accuracy: 0.5460 - val_loss: 1.3819 - val_accuracy: 0.5472\n",
      "Epoch 5/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 1.2282 - accuracy: 0.5675 - val_loss: 1.2950 - val_accuracy: 0.5655\n",
      "Epoch 6/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 1.1741 - accuracy: 0.5916 - val_loss: 1.2397 - val_accuracy: 0.5970\n",
      "Epoch 7/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 1.1321 - accuracy: 0.6009 - val_loss: 1.2010 - val_accuracy: 0.5953\n",
      "Epoch 8/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 1.0855 - accuracy: 0.6263 - val_loss: 1.1302 - val_accuracy: 0.6262\n",
      "Epoch 9/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 1.0376 - accuracy: 0.6382 - val_loss: 1.0955 - val_accuracy: 0.6480\n",
      "Epoch 10/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.9765 - accuracy: 0.6600 - val_loss: 1.0494 - val_accuracy: 0.6491\n",
      "Epoch 11/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.9689 - accuracy: 0.6654 - val_loss: 1.0378 - val_accuracy: 0.6359\n",
      "Epoch 12/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.9138 - accuracy: 0.6905 - val_loss: 0.9739 - val_accuracy: 0.6817\n",
      "Epoch 13/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.8992 - accuracy: 0.6895 - val_loss: 0.9553 - val_accuracy: 0.6926\n",
      "Epoch 14/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.8691 - accuracy: 0.6998 - val_loss: 0.9349 - val_accuracy: 0.6875\n",
      "Epoch 15/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.8456 - accuracy: 0.7044 - val_loss: 0.9059 - val_accuracy: 0.6880\n",
      "Epoch 16/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.8097 - accuracy: 0.7200 - val_loss: 0.8689 - val_accuracy: 0.7115\n",
      "Epoch 17/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.7867 - accuracy: 0.7301 - val_loss: 0.8239 - val_accuracy: 0.7207\n",
      "Epoch 18/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.7572 - accuracy: 0.7470 - val_loss: 0.8729 - val_accuracy: 0.6983\n",
      "Epoch 19/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.7292 - accuracy: 0.7528 - val_loss: 0.8178 - val_accuracy: 0.7321\n",
      "Epoch 20/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.7281 - accuracy: 0.7552 - val_loss: 0.7764 - val_accuracy: 0.7464\n",
      "Epoch 21/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.6911 - accuracy: 0.7642 - val_loss: 0.7214 - val_accuracy: 0.7687\n",
      "Epoch 22/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.6791 - accuracy: 0.7672 - val_loss: 0.7612 - val_accuracy: 0.7436\n",
      "Epoch 23/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.6558 - accuracy: 0.7755 - val_loss: 0.7135 - val_accuracy: 0.7665\n",
      "Epoch 24/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.6581 - accuracy: 0.7777 - val_loss: 0.6809 - val_accuracy: 0.7859\n",
      "Epoch 25/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.6234 - accuracy: 0.7893 - val_loss: 0.6921 - val_accuracy: 0.7790\n",
      "Epoch 26/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.6062 - accuracy: 0.8009 - val_loss: 0.6418 - val_accuracy: 0.7939\n",
      "Epoch 27/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.5796 - accuracy: 0.8066 - val_loss: 0.6308 - val_accuracy: 0.7871\n",
      "Epoch 28/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.5769 - accuracy: 0.8083 - val_loss: 0.6388 - val_accuracy: 0.7962\n",
      "Epoch 29/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.5705 - accuracy: 0.8073 - val_loss: 0.5989 - val_accuracy: 0.8180\n",
      "Epoch 30/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.5498 - accuracy: 0.8146 - val_loss: 0.5775 - val_accuracy: 0.8185\n",
      "Epoch 31/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.5382 - accuracy: 0.8172 - val_loss: 0.5649 - val_accuracy: 0.8226\n",
      "Epoch 32/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.5153 - accuracy: 0.8251 - val_loss: 0.5669 - val_accuracy: 0.8208\n",
      "Epoch 33/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.5154 - accuracy: 0.8326 - val_loss: 0.5478 - val_accuracy: 0.8248\n",
      "Epoch 34/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.5162 - accuracy: 0.8273 - val_loss: 0.5340 - val_accuracy: 0.8386\n",
      "Epoch 35/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.4914 - accuracy: 0.8318 - val_loss: 0.5230 - val_accuracy: 0.8346\n",
      "Epoch 36/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.4899 - accuracy: 0.8329 - val_loss: 0.5233 - val_accuracy: 0.8369\n",
      "Epoch 37/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.4732 - accuracy: 0.8421 - val_loss: 0.5091 - val_accuracy: 0.8409\n",
      "Epoch 38/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.4665 - accuracy: 0.8377 - val_loss: 0.5015 - val_accuracy: 0.8443\n",
      "Epoch 39/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.4442 - accuracy: 0.8501 - val_loss: 0.4876 - val_accuracy: 0.8432\n",
      "Epoch 40/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.4347 - accuracy: 0.8531 - val_loss: 0.4892 - val_accuracy: 0.8460\n",
      "Epoch 41/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.4368 - accuracy: 0.8541 - val_loss: 0.4901 - val_accuracy: 0.8477\n",
      "Epoch 42/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.4197 - accuracy: 0.8587 - val_loss: 0.4702 - val_accuracy: 0.8500\n",
      "Epoch 43/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.4093 - accuracy: 0.8581 - val_loss: 0.4743 - val_accuracy: 0.8449\n",
      "Epoch 44/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.4002 - accuracy: 0.8633 - val_loss: 0.4771 - val_accuracy: 0.8472\n",
      "Epoch 45/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.3875 - accuracy: 0.8706 - val_loss: 0.4473 - val_accuracy: 0.8592\n",
      "Epoch 46/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.3785 - accuracy: 0.8700 - val_loss: 0.4491 - val_accuracy: 0.8580\n",
      "Epoch 47/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.3885 - accuracy: 0.8706 - val_loss: 0.4775 - val_accuracy: 0.8437\n",
      "Epoch 48/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.3754 - accuracy: 0.8753 - val_loss: 0.4565 - val_accuracy: 0.8495\n",
      "Epoch 49/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.3737 - accuracy: 0.8707 - val_loss: 0.4170 - val_accuracy: 0.8706\n",
      "Epoch 50/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.3604 - accuracy: 0.8754 - val_loss: 0.4163 - val_accuracy: 0.8769\n",
      "Epoch 51/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.3562 - accuracy: 0.8803 - val_loss: 0.4241 - val_accuracy: 0.8626\n",
      "Epoch 52/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.3379 - accuracy: 0.8858 - val_loss: 0.4100 - val_accuracy: 0.8689\n",
      "Epoch 53/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.3460 - accuracy: 0.8767 - val_loss: 0.3984 - val_accuracy: 0.8746\n",
      "Epoch 54/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.3325 - accuracy: 0.8835 - val_loss: 0.4038 - val_accuracy: 0.8689\n",
      "Epoch 55/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.3421 - accuracy: 0.8799 - val_loss: 0.4308 - val_accuracy: 0.8620\n",
      "Epoch 56/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.3240 - accuracy: 0.8918 - val_loss: 0.4101 - val_accuracy: 0.8632\n",
      "Epoch 57/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.3189 - accuracy: 0.8899 - val_loss: 0.3934 - val_accuracy: 0.8838\n",
      "Epoch 58/72\n",
      "6985/6985 [==============================] - 15s 2ms/step - loss: 0.3208 - accuracy: 0.8915 - val_loss: 0.3949 - val_accuracy: 0.8735\n",
      "Epoch 59/72\n",
      "6985/6985 [==============================] - 16s 2ms/step - loss: 0.3166 - accuracy: 0.8925 - val_loss: 0.3875 - val_accuracy: 0.8724\n",
      "Epoch 60/72\n",
      "3840/6985 [===============>..............] - ETA: 6s - loss: 0.3105 - accuracy: 0.8898"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "#num_epochs = 12\n",
    "#num_batch_size = 128\n",
    "\n",
    "num_epochs = 72\n",
    "num_batch_size = 256\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
