{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               10496     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 78,858\n",
      "Trainable params: 78,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 11.7916%\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6985 samples, validate on 1747 samples\n",
      "Epoch 1/100\n",
      "6985/6985 [==============================] - 1s 99us/step - loss: 2.0287 - accuracy: 0.2998 - val_loss: 1.8355 - val_accuracy: 0.3778\n",
      "Epoch 2/100\n",
      "6985/6985 [==============================] - 1s 88us/step - loss: 1.8871 - accuracy: 0.3402 - val_loss: 1.6856 - val_accuracy: 0.4516\n",
      "Epoch 3/100\n",
      "6985/6985 [==============================] - 1s 86us/step - loss: 1.7689 - accuracy: 0.3774 - val_loss: 1.5609 - val_accuracy: 0.4751\n",
      "Epoch 4/100\n",
      "6985/6985 [==============================] - 1s 88us/step - loss: 1.6799 - accuracy: 0.4087 - val_loss: 1.4408 - val_accuracy: 0.5255\n",
      "Epoch 5/100\n",
      "6985/6985 [==============================] - 1s 90us/step - loss: 1.5815 - accuracy: 0.4551 - val_loss: 1.3553 - val_accuracy: 0.5661\n",
      "Epoch 6/100\n",
      "6985/6985 [==============================] - 1s 111us/step - loss: 1.4953 - accuracy: 0.4790 - val_loss: 1.2747 - val_accuracy: 0.5953\n",
      "Epoch 7/100\n",
      "6985/6985 [==============================] - 1s 107us/step - loss: 1.4345 - accuracy: 0.5047 - val_loss: 1.1773 - val_accuracy: 0.6285\n",
      "Epoch 8/100\n",
      "6985/6985 [==============================] - 1s 115us/step - loss: 1.3620 - accuracy: 0.5321 - val_loss: 1.1184 - val_accuracy: 0.6394\n",
      "Epoch 9/100\n",
      "6985/6985 [==============================] - 1s 115us/step - loss: 1.2980 - accuracy: 0.5512 - val_loss: 1.0646 - val_accuracy: 0.6720\n",
      "Epoch 10/100\n",
      "6985/6985 [==============================] - 1s 114us/step - loss: 1.2658 - accuracy: 0.5642 - val_loss: 1.0188 - val_accuracy: 0.6669\n",
      "Epoch 11/100\n",
      "6985/6985 [==============================] - 1s 114us/step - loss: 1.2063 - accuracy: 0.5873 - val_loss: 0.9789 - val_accuracy: 0.6886\n",
      "Epoch 12/100\n",
      "6985/6985 [==============================] - 1s 114us/step - loss: 1.1600 - accuracy: 0.5997 - val_loss: 0.9377 - val_accuracy: 0.6932\n",
      "Epoch 13/100\n",
      "6985/6985 [==============================] - 1s 114us/step - loss: 1.1110 - accuracy: 0.6173 - val_loss: 0.8893 - val_accuracy: 0.7121\n",
      "Epoch 14/100\n",
      "6985/6985 [==============================] - 1s 117us/step - loss: 1.0728 - accuracy: 0.6318 - val_loss: 0.8660 - val_accuracy: 0.7315\n",
      "Epoch 15/100\n",
      "6985/6985 [==============================] - 1s 111us/step - loss: 1.0597 - accuracy: 0.6315 - val_loss: 0.8405 - val_accuracy: 0.7367\n",
      "Epoch 16/100\n",
      "6985/6985 [==============================] - 1s 119us/step - loss: 1.0288 - accuracy: 0.6543 - val_loss: 0.8200 - val_accuracy: 0.7350\n",
      "Epoch 17/100\n",
      "6985/6985 [==============================] - 1s 103us/step - loss: 0.9834 - accuracy: 0.6633 - val_loss: 0.7752 - val_accuracy: 0.7556\n",
      "Epoch 18/100\n",
      "6985/6985 [==============================] - ETA: 0s - loss: 0.9764 - accuracy: 0.67 - 1s 111us/step - loss: 0.9761 - accuracy: 0.6733 - val_loss: 0.7530 - val_accuracy: 0.7653\n",
      "Epoch 19/100\n",
      "6985/6985 [==============================] - 1s 110us/step - loss: 0.9363 - accuracy: 0.6840 - val_loss: 0.7579 - val_accuracy: 0.7499\n",
      "Epoch 20/100\n",
      "6985/6985 [==============================] - 1s 112us/step - loss: 0.9124 - accuracy: 0.6906 - val_loss: 0.7040 - val_accuracy: 0.7876\n",
      "Epoch 21/100\n",
      "6985/6985 [==============================] - 1s 115us/step - loss: 0.8970 - accuracy: 0.6946 - val_loss: 0.6801 - val_accuracy: 0.7819\n",
      "Epoch 22/100\n",
      "6985/6985 [==============================] - 1s 115us/step - loss: 0.8853 - accuracy: 0.6943 - val_loss: 0.6950 - val_accuracy: 0.7951\n",
      "Epoch 23/100\n",
      "6985/6985 [==============================] - 1s 115us/step - loss: 0.8703 - accuracy: 0.7051 - val_loss: 0.6709 - val_accuracy: 0.8054\n",
      "Epoch 24/100\n",
      "6985/6985 [==============================] - 1s 98us/step - loss: 0.8316 - accuracy: 0.7141 - val_loss: 0.6501 - val_accuracy: 0.7899\n",
      "Epoch 25/100\n",
      "6985/6985 [==============================] - 1s 96us/step - loss: 0.8278 - accuracy: 0.7142 - val_loss: 0.6240 - val_accuracy: 0.7991\n",
      "Epoch 26/100\n",
      "6985/6985 [==============================] - 1s 112us/step - loss: 0.8162 - accuracy: 0.7246 - val_loss: 0.6425 - val_accuracy: 0.8088\n",
      "Epoch 27/100\n",
      "6985/6985 [==============================] - 1s 116us/step - loss: 0.8021 - accuracy: 0.7244 - val_loss: 0.6187 - val_accuracy: 0.8105\n",
      "Epoch 28/100\n",
      "6985/6985 [==============================] - 1s 105us/step - loss: 0.7796 - accuracy: 0.7336 - val_loss: 0.6287 - val_accuracy: 0.8094\n",
      "Epoch 29/100\n",
      "6985/6985 [==============================] - 1s 105us/step - loss: 0.7752 - accuracy: 0.7307 - val_loss: 0.5949 - val_accuracy: 0.8145\n",
      "Epoch 30/100\n",
      "6985/6985 [==============================] - 1s 104us/step - loss: 0.7597 - accuracy: 0.7396 - val_loss: 0.5984 - val_accuracy: 0.8197\n",
      "Epoch 31/100\n",
      "6985/6985 [==============================] - 1s 106us/step - loss: 0.7557 - accuracy: 0.7473 - val_loss: 0.5993 - val_accuracy: 0.8214\n",
      "Epoch 32/100\n",
      "6985/6985 [==============================] - 1s 100us/step - loss: 0.7200 - accuracy: 0.7515 - val_loss: 0.5686 - val_accuracy: 0.8271\n",
      "Epoch 33/100\n",
      "6985/6985 [==============================] - 1s 102us/step - loss: 0.7255 - accuracy: 0.7450 - val_loss: 0.5479 - val_accuracy: 0.8334\n",
      "Epoch 34/100\n",
      "6985/6985 [==============================] - 1s 103us/step - loss: 0.7393 - accuracy: 0.7492 - val_loss: 0.5325 - val_accuracy: 0.8460\n",
      "Epoch 35/100\n",
      "6985/6985 [==============================] - 1s 113us/step - loss: 0.7073 - accuracy: 0.7572 - val_loss: 0.5507 - val_accuracy: 0.8334\n",
      "Epoch 36/100\n",
      "6985/6985 [==============================] - 1s 113us/step - loss: 0.7144 - accuracy: 0.7482 - val_loss: 0.5429 - val_accuracy: 0.8317\n",
      "Epoch 37/100\n",
      "6985/6985 [==============================] - 1s 113us/step - loss: 0.7066 - accuracy: 0.7625 - val_loss: 0.5298 - val_accuracy: 0.8437\n",
      "Epoch 38/100\n",
      "6985/6985 [==============================] - 1s 113us/step - loss: 0.6605 - accuracy: 0.7744 - val_loss: 0.5198 - val_accuracy: 0.8506\n",
      "Epoch 39/100\n",
      "6985/6985 [==============================] - 1s 116us/step - loss: 0.6790 - accuracy: 0.7652 - val_loss: 0.5742 - val_accuracy: 0.8214\n",
      "Epoch 40/100\n",
      "6985/6985 [==============================] - 1s 114us/step - loss: 0.7062 - accuracy: 0.7622 - val_loss: 0.5123 - val_accuracy: 0.8426\n",
      "Epoch 41/100\n",
      "6985/6985 [==============================] - 1s 113us/step - loss: 0.6610 - accuracy: 0.7749 - val_loss: 0.5377 - val_accuracy: 0.8495\n",
      "Epoch 42/100\n",
      "6985/6985 [==============================] - 1s 114us/step - loss: 0.6748 - accuracy: 0.7705 - val_loss: 0.5131 - val_accuracy: 0.8426\n",
      "Epoch 43/100\n",
      "6985/6985 [==============================] - 1s 112us/step - loss: 0.6677 - accuracy: 0.7699 - val_loss: 0.5089 - val_accuracy: 0.8517\n",
      "Epoch 44/100\n",
      "6985/6985 [==============================] - 1s 111us/step - loss: 0.6527 - accuracy: 0.7800 - val_loss: 0.5162 - val_accuracy: 0.8437\n",
      "Epoch 45/100\n",
      "6985/6985 [==============================] - 1s 109us/step - loss: 0.6478 - accuracy: 0.7837 - val_loss: 0.5099 - val_accuracy: 0.8563\n",
      "Epoch 46/100\n",
      "6985/6985 [==============================] - 1s 111us/step - loss: 0.6565 - accuracy: 0.7758 - val_loss: 0.5076 - val_accuracy: 0.8506\n",
      "Epoch 47/100\n",
      "6985/6985 [==============================] - 1s 111us/step - loss: 0.6474 - accuracy: 0.7782 - val_loss: 0.5035 - val_accuracy: 0.8506\n",
      "Epoch 48/100\n",
      "6985/6985 [==============================] - 1s 104us/step - loss: 0.6392 - accuracy: 0.7812 - val_loss: 0.4900 - val_accuracy: 0.8517\n",
      "Epoch 49/100\n",
      "6985/6985 [==============================] - 1s 112us/step - loss: 0.6217 - accuracy: 0.7933 - val_loss: 0.4921 - val_accuracy: 0.8523\n",
      "Epoch 50/100\n",
      "6985/6985 [==============================] - 1s 111us/step - loss: 0.6098 - accuracy: 0.7943 - val_loss: 0.4827 - val_accuracy: 0.8500\n",
      "Epoch 51/100\n",
      "6985/6985 [==============================] - 1s 115us/step - loss: 0.6180 - accuracy: 0.7901 - val_loss: 0.4802 - val_accuracy: 0.8598\n",
      "Epoch 52/100\n",
      "6985/6985 [==============================] - 1s 115us/step - loss: 0.5977 - accuracy: 0.7981 - val_loss: 0.4563 - val_accuracy: 0.8586\n",
      "Epoch 53/100\n",
      "6985/6985 [==============================] - 1s 116us/step - loss: 0.6062 - accuracy: 0.7954 - val_loss: 0.4847 - val_accuracy: 0.8701\n",
      "Epoch 54/100\n",
      "6985/6985 [==============================] - 1s 114us/step - loss: 0.5958 - accuracy: 0.7980 - val_loss: 0.4818 - val_accuracy: 0.8632\n",
      "Epoch 55/100\n",
      "6985/6985 [==============================] - 1s 113us/step - loss: 0.6010 - accuracy: 0.7953 - val_loss: 0.4664 - val_accuracy: 0.8632\n",
      "Epoch 56/100\n",
      "6985/6985 [==============================] - 1s 114us/step - loss: 0.5732 - accuracy: 0.8003 - val_loss: 0.4709 - val_accuracy: 0.8649\n",
      "Epoch 57/100\n",
      "6985/6985 [==============================] - 1s 116us/step - loss: 0.5901 - accuracy: 0.8001 - val_loss: 0.4689 - val_accuracy: 0.8661\n",
      "Epoch 58/100\n",
      "6985/6985 [==============================] - 1s 113us/step - loss: 0.5972 - accuracy: 0.8011 - val_loss: 0.4798 - val_accuracy: 0.8592\n",
      "Epoch 59/100\n",
      "6985/6985 [==============================] - 1s 115us/step - loss: 0.6043 - accuracy: 0.7964 - val_loss: 0.4547 - val_accuracy: 0.8712\n",
      "Epoch 60/100\n",
      "6985/6985 [==============================] - 1s 112us/step - loss: 0.5845 - accuracy: 0.8021 - val_loss: 0.4450 - val_accuracy: 0.8718\n",
      "Epoch 61/100\n",
      "6985/6985 [==============================] - 1s 100us/step - loss: 0.5909 - accuracy: 0.8021 - val_loss: 0.4758 - val_accuracy: 0.8638\n",
      "Epoch 62/100\n",
      "6985/6985 [==============================] - 1s 104us/step - loss: 0.5921 - accuracy: 0.7960 - val_loss: 0.4770 - val_accuracy: 0.8615\n",
      "Epoch 63/100\n",
      "6985/6985 [==============================] - 1s 116us/step - loss: 0.5901 - accuracy: 0.8004 - val_loss: 0.4715 - val_accuracy: 0.8620\n",
      "Epoch 64/100\n",
      "6985/6985 [==============================] - 1s 117us/step - loss: 0.5762 - accuracy: 0.8094 - val_loss: 0.4562 - val_accuracy: 0.8655\n",
      "Epoch 65/100\n",
      "6985/6985 [==============================] - 1s 117us/step - loss: 0.5701 - accuracy: 0.8094 - val_loss: 0.4429 - val_accuracy: 0.8678\n",
      "Epoch 66/100\n",
      "6985/6985 [==============================] - 1s 117us/step - loss: 0.5599 - accuracy: 0.8082 - val_loss: 0.4414 - val_accuracy: 0.8724\n",
      "Epoch 67/100\n",
      "6985/6985 [==============================] - 1s 118us/step - loss: 0.5663 - accuracy: 0.8050 - val_loss: 0.4723 - val_accuracy: 0.8615\n",
      "Epoch 68/100\n",
      "6985/6985 [==============================] - 1s 107us/step - loss: 0.5600 - accuracy: 0.8147 - val_loss: 0.4290 - val_accuracy: 0.8752\n",
      "Epoch 69/100\n",
      "6985/6985 [==============================] - 1s 107us/step - loss: 0.5691 - accuracy: 0.8110 - val_loss: 0.4678 - val_accuracy: 0.8724\n",
      "Epoch 70/100\n",
      "6985/6985 [==============================] - 1s 100us/step - loss: 0.5551 - accuracy: 0.8135 - val_loss: 0.4297 - val_accuracy: 0.8781\n",
      "Epoch 71/100\n",
      "6985/6985 [==============================] - 1s 103us/step - loss: 0.5524 - accuracy: 0.8159 - val_loss: 0.4612 - val_accuracy: 0.8752\n",
      "Epoch 72/100\n",
      "6985/6985 [==============================] - 1s 101us/step - loss: 0.5465 - accuracy: 0.8157 - val_loss: 0.4257 - val_accuracy: 0.8792\n",
      "Epoch 73/100\n",
      "6985/6985 [==============================] - 1s 104us/step - loss: 0.5416 - accuracy: 0.8195 - val_loss: 0.4553 - val_accuracy: 0.8769\n",
      "Epoch 74/100\n",
      "6985/6985 [==============================] - 1s 103us/step - loss: 0.5491 - accuracy: 0.8155 - val_loss: 0.4673 - val_accuracy: 0.8712\n",
      "Epoch 75/100\n",
      "6985/6985 [==============================] - 1s 106us/step - loss: 0.5408 - accuracy: 0.8172 - val_loss: 0.4613 - val_accuracy: 0.8804\n",
      "Epoch 76/100\n",
      "6985/6985 [==============================] - 1s 116us/step - loss: 0.5203 - accuracy: 0.8209 - val_loss: 0.4351 - val_accuracy: 0.8746\n",
      "Epoch 77/100\n",
      "6985/6985 [==============================] - 1s 117us/step - loss: 0.5554 - accuracy: 0.8135 - val_loss: 0.4465 - val_accuracy: 0.8752\n",
      "Epoch 78/100\n",
      "6985/6985 [==============================] - 1s 116us/step - loss: 0.5453 - accuracy: 0.8156 - val_loss: 0.4429 - val_accuracy: 0.8643\n",
      "Epoch 79/100\n",
      "6985/6985 [==============================] - 1s 116us/step - loss: 0.5034 - accuracy: 0.8286 - val_loss: 0.4119 - val_accuracy: 0.8815\n",
      "Epoch 80/100\n",
      "6985/6985 [==============================] - 1s 116us/step - loss: 0.5069 - accuracy: 0.8269 - val_loss: 0.4263 - val_accuracy: 0.8815\n",
      "Epoch 81/100\n",
      "6985/6985 [==============================] - 1s 112us/step - loss: 0.5253 - accuracy: 0.8226 - val_loss: 0.4503 - val_accuracy: 0.8746\n",
      "Epoch 82/100\n",
      "6985/6985 [==============================] - 1s 118us/step - loss: 0.5220 - accuracy: 0.8259 - val_loss: 0.4250 - val_accuracy: 0.8712\n",
      "Epoch 83/100\n",
      "6985/6985 [==============================] - 1s 117us/step - loss: 0.5182 - accuracy: 0.8281 - val_loss: 0.4036 - val_accuracy: 0.8878\n",
      "Epoch 84/100\n",
      "6985/6985 [==============================] - 1s 117us/step - loss: 0.5275 - accuracy: 0.8195 - val_loss: 0.4247 - val_accuracy: 0.8844\n",
      "Epoch 85/100\n",
      "6985/6985 [==============================] - 1s 116us/step - loss: 0.5223 - accuracy: 0.8251 - val_loss: 0.4253 - val_accuracy: 0.8764\n",
      "Epoch 86/100\n",
      "6985/6985 [==============================] - 1s 115us/step - loss: 0.5249 - accuracy: 0.8242 - val_loss: 0.4259 - val_accuracy: 0.8798\n",
      "Epoch 87/100\n",
      "6985/6985 [==============================] - 1s 106us/step - loss: 0.5249 - accuracy: 0.8230 - val_loss: 0.4530 - val_accuracy: 0.8718\n",
      "Epoch 88/100\n",
      "6985/6985 [==============================] - 1s 103us/step - loss: 0.5098 - accuracy: 0.8271 - val_loss: 0.4111 - val_accuracy: 0.8832\n",
      "Epoch 89/100\n",
      "6985/6985 [==============================] - 1s 117us/step - loss: 0.5020 - accuracy: 0.8281 - val_loss: 0.4222 - val_accuracy: 0.8861\n",
      "Epoch 90/100\n",
      "6985/6985 [==============================] - 1s 107us/step - loss: 0.5168 - accuracy: 0.8282 - val_loss: 0.4136 - val_accuracy: 0.8786\n",
      "Epoch 91/100\n",
      "6985/6985 [==============================] - 1s 113us/step - loss: 0.5221 - accuracy: 0.8279 - val_loss: 0.4354 - val_accuracy: 0.8729\n",
      "Epoch 92/100\n",
      "6985/6985 [==============================] - 1s 114us/step - loss: 0.5179 - accuracy: 0.8292 - val_loss: 0.4048 - val_accuracy: 0.8884\n",
      "Epoch 93/100\n",
      "6985/6985 [==============================] - 1s 110us/step - loss: 0.5245 - accuracy: 0.8286 - val_loss: 0.4247 - val_accuracy: 0.8827\n",
      "Epoch 94/100\n",
      "6985/6985 [==============================] - 1s 103us/step - loss: 0.5237 - accuracy: 0.8255 - val_loss: 0.4439 - val_accuracy: 0.8849\n",
      "Epoch 95/100\n",
      "6985/6985 [==============================] - 1s 106us/step - loss: 0.4976 - accuracy: 0.8338 - val_loss: 0.4524 - val_accuracy: 0.8838\n",
      "Epoch 96/100\n",
      "6985/6985 [==============================] - 1s 106us/step - loss: 0.5023 - accuracy: 0.8356 - val_loss: 0.4327 - val_accuracy: 0.8809\n",
      "Epoch 97/100\n",
      "6985/6985 [==============================] - 1s 104us/step - loss: 0.5127 - accuracy: 0.8288 - val_loss: 0.4110 - val_accuracy: 0.8890\n",
      "Epoch 98/100\n",
      "6985/6985 [==============================] - 1s 101us/step - loss: 0.4721 - accuracy: 0.8441 - val_loss: 0.4370 - val_accuracy: 0.8890\n",
      "Epoch 99/100\n",
      "6985/6985 [==============================] - 1s 104us/step - loss: 0.5037 - accuracy: 0.8331 - val_loss: 0.4297 - val_accuracy: 0.8861\n",
      "Epoch 100/100\n",
      "6985/6985 [==============================] - 1s 102us/step - loss: 0.4970 - accuracy: 0.8341 - val_loss: 0.4431 - val_accuracy: 0.8901\n",
      "Training completed in timeL  0:01:16.846708\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "duration = datetime.now() -start\n",
    "print(\"Training completed in timeL \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6985/6985 [==============================] - 0s 32us/step\n",
      "Training Accuracy:  0.9297065138816833\n",
      "1747/1747 [==============================] - 0s 35us/step\n",
      "Training Accuracy:  0.8900973200798035\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train, verbose=1)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Training Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
